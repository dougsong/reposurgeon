= Helping with the Go translation =

We presently need help in two areas:

1. Fixing bugs in the Go translation

2. Speed tuning

== Fixing translation bugs ==

You can help by fixing command handlers to have correct behavior on a
regression test that succeeds under the Python implementation but
fails under Go.

To build the Go tools, simply run "make" in the toplevel directory.
This also builds the suite documentation.

'make gotest' runs the Go unit tests.  These are pretty stable.

'make goregress' runs the full regression-test suite using the
Go binary.  It will bail out on the first error.  Presently it
dies on the x-blob-id test; this is expected.

There are tools and makefile productions for finer-grained testing.  
Their behavior is cinrolled by two variables:

REPOSURGEON: either reposurgeon (the default) or goreposurgeon

STOPOUT: 1 (the default) produces a bailout after the first failed
test.  Set it to 0 to continue after failed tests - you have to do
this on the make command line, e.g. "cd test; make STOPOUT=0
fi-regress".  Note, the output from this may be voluminous and
unuseful.

make goregress forces REPOSURGEON=goreposurgeon.  It runs fi-regress which is
the inner production for general regression tests.

To run a single test under Go,

   cd test; REPOSURGEON=../goreposurgeon ./singletest x-foo

will check the actual result of the script in x-foo.tst against its expected
output in x-foo.chk.  No output other than the test notice is good.  The
Python version passes all these tests.

The following tests presently fail:

x-reorder: toposort code is busted.
x-branchify.tst: "permission information may be lost" nonfatal failure"
x-debranch.tst: slice bounds out of range error
x-debranch2.tst: slice bounds out of range error
x-lint.tst: "permission information may be lost" nonfatal failure"
x-references.tst: index out of range crash
x-split-dir.tst: nonfatal failure to resolve mergeinfo
x-split.tst: index error crash
x-subdir.tst: failure to fill in branch roots correctly
x-tagretract.tst: index out of range error
x-treecontents.tst: nonfatal error
x-userignores.tst: cannot resolve mergeinfo

The reparent test presently succeeds, but the toposort has been
commented out.

The next steps after these will be testing coalescence, extractor classes,
and the Subversion load tests.

== Tuning for speed ==

The goal of this port is to improve conversion performance on large
repositories by an order of magnitude or more, with the horrible
example being the GCC subversion history.  Trial runs with the Python
version were taking 9-10 hours!

If you are already a Go expert, you can help by tuning for speed.  The
most important single operations to speed up are fast-import stream reads and
(when the Subversion support is working) Subversion dump stream reads.

First thing to do is make a test load.  The reposurgeon history itself is
large enough to be a useful one.  So:

$ goreposurgeon "read ." "write >reposurgeon.fi"

The ability to dump profile data is built into reposurgeon itself:

$ goreposurgeon "verbose 1" "profile reposurgeon.prof" "read <rs.fi" "profile"

Once you have the profile data you can sic the profile viewer on it.
Have graphviz installed and do

go tool pprof goreposurgeon rs.prof

There are lots of ways to explore the data but single most interesting one
is to enter "web" and look at your browser. The size of each box is proportional
to the number of profiler samples it appears in.  "top10" gives you the same
data in tabular form:

      flat  flat%   sum%        cum   cum%
     1.41s 22.45% 22.45%      1.43s 22.77%  syscall.Syscall
     1.11s 17.68% 40.13%      2.22s 35.35%  runtime.scanobject
     0.75s 11.94% 52.07%      0.75s 11.94%  runtime.greyobject
     0.58s  9.24% 61.31%      0.58s  9.24%  runtime.memmove

This is telling us that (a) disk I/O (syscall.Syscall) is slow, but garbage
collection overhead dominates (runtime.scanobject and runtime.greyobject, 47%).
That runtime.memmove is probably array copies during append operations.

To go faster we need to exercise the allocator less.  In a way this is
good news - it suggests we don't have a big-O/algorithmic problem.

The obvious thing to do first is a search-and-destroy for heap escapes.
We can't avoid doing a lot of allocation; what we can do is avoid creating
lots of short-lived heap objects that will churn heap storage and trigger GC.

Some references:

https://blog.golang.org/profiling-go-programs

https://github.com/google/pprof/blob/master/doc/README.md

https://www.signalfx.com/blog/a-pattern-for-optimizing-go-2/

http://www.agardner.me/golang/garbage/collection/gc/escape/analysis/2015/10/18/go-escape-analysis.html
